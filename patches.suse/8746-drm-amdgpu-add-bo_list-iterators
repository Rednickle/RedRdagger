From: =?UTF-8?q?Christian=20K=C3=B6nig?= <christian.koenig@amd.com>
Date: Mon, 30 Jul 2018 15:37:46 +0200
Subject: drm/amdgpu: add bo_list iterators
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Git-commit: 39f7f69a6054bb9777b47b6afdb5ce2fae30dbee
Patch-mainline: v4.19-rc1
References: FATE#326289 FATE#326079 FATE#326049 FATE#322398 FATE#326166

Add helpers to iterate over all entries in a bo_list.

Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
Reviewed-by: Chunming  Zhou <david1.zhou@amd.com>
Acked-by: Huang Rui <ray.huang@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Acked-by: Petr Tesarik <ptesarik@suse.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c |   21 ++++++-----
 drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.h |   10 +++++
 drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c      |   51 ++++++++++++----------------
 3 files changed, 43 insertions(+), 39 deletions(-)

--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.c
@@ -43,12 +43,12 @@ static int amdgpu_bo_list_set(struct amd
 
 static void amdgpu_bo_list_release_rcu(struct kref *ref)
 {
-	unsigned i;
 	struct amdgpu_bo_list *list = container_of(ref, struct amdgpu_bo_list,
 						   refcount);
+	struct amdgpu_bo_list_entry *e;
 
-	for (i = 0; i < list->num_entries; ++i)
-		amdgpu_bo_unref(&list->array[i].robj);
+	amdgpu_bo_list_for_each_entry(e, list)
+		amdgpu_bo_unref(&e->robj);
 
 	kvfree(list->array);
 	kfree_rcu(list, rhead);
@@ -103,6 +103,7 @@ static int amdgpu_bo_list_set(struct amd
 	struct amdgpu_bo *oa_obj = adev->gds.oa_gfx_bo;
 
 	unsigned last_entry = 0, first_userptr = num_entries;
+	struct amdgpu_bo_list_entry *e;
 	uint64_t total_size = 0;
 	unsigned i;
 	int r;
@@ -156,7 +157,7 @@ static int amdgpu_bo_list_set(struct amd
 		trace_amdgpu_bo_list_set(list, entry->robj);
 	}
 
-	for (i = 0; i < list->num_entries; ++i)
+	amdgpu_bo_list_for_each_entry(e, list)
 		amdgpu_bo_unref(&list->array[i].robj);
 
 	kvfree(list->array);
@@ -201,6 +202,7 @@ void amdgpu_bo_list_get_list(struct amdg
 	 * concatenated in descending order.
 	 */
 	struct list_head bucket[AMDGPU_BO_LIST_NUM_BUCKETS];
+	struct amdgpu_bo_list_entry *e;
 	unsigned i;
 
 	for (i = 0; i < AMDGPU_BO_LIST_NUM_BUCKETS; i++)
@@ -211,14 +213,13 @@ void amdgpu_bo_list_get_list(struct amdg
 	 * in the list, the sort mustn't change the ordering of buffers
 	 * with the same priority, i.e. it must be stable.
 	 */
-	for (i = 0; i < list->num_entries; i++) {
-		unsigned priority = list->array[i].priority;
+	amdgpu_bo_list_for_each_entry(e, list) {
+		unsigned priority = e->priority;
 
-		if (!list->array[i].robj->parent)
-			list_add_tail(&list->array[i].tv.head,
-				      &bucket[priority]);
+		if (!e->robj->parent)
+			list_add_tail(&e->tv.head, &bucket[priority]);
 
-		list->array[i].user_pages = NULL;
+		e->user_pages = NULL;
 	}
 
 	/* Connect the sorted buckets in the output list. */
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_bo_list.h
@@ -65,4 +65,14 @@ int amdgpu_bo_list_create(struct amdgpu_
 				 unsigned num_entries,
 				 struct amdgpu_bo_list **list);
 
+#define amdgpu_bo_list_for_each_entry(e, list) \
+	for (e = &(list)->array[0]; \
+	     e != &(list)->array[(list)->num_entries]; \
+	     ++e)
+
+#define amdgpu_bo_list_for_each_userptr_entry(e, list) \
+	for (e = &(list)->array[(list)->first_userptr]; \
+	     e != &(list)->array[(list)->num_entries]; \
+	     ++e)
+
 #endif
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -563,10 +563,10 @@ static int amdgpu_cs_parser_bos(struct a
 	struct amdgpu_fpriv *fpriv = p->filp->driver_priv;
 	struct amdgpu_bo_list_entry *e;
 	struct list_head duplicates;
-	unsigned i, tries = 10;
 	struct amdgpu_bo *gds;
 	struct amdgpu_bo *gws;
 	struct amdgpu_bo *oa;
+	unsigned tries = 10;
 	int r;
 
 	INIT_LIST_HEAD(&p->validated);
@@ -596,7 +596,6 @@ static int amdgpu_cs_parser_bos(struct a
 
 	while (1) {
 		struct list_head need_pages;
-		unsigned i;
 
 		r = ttm_eu_reserve_buffers(&p->ticket, &p->validated, true,
 					   &duplicates);
@@ -611,12 +610,8 @@ static int amdgpu_cs_parser_bos(struct a
 			break;
 
 		INIT_LIST_HEAD(&need_pages);
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			struct amdgpu_bo *bo;
-
-			e = &p->bo_list->array[i];
-			bo = e->robj;
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+			struct amdgpu_bo *bo = e->robj;
 
 			if (amdgpu_ttm_tt_userptr_invalidated(bo->tbo.ttm,
 				 &e->user_invalidated) && e->user_pages) {
@@ -710,16 +705,14 @@ static int amdgpu_cs_parser_bos(struct a
 
 	if (p->bo_list) {
 		struct amdgpu_vm *vm = &fpriv->vm;
-		unsigned i;
+		struct amdgpu_bo_list_entry *e;
 
 		gds = p->bo_list->gds_obj;
 		gws = p->bo_list->gws_obj;
 		oa = p->bo_list->oa_obj;
-		for (i = 0; i < p->bo_list->num_entries; i++) {
-			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
 
-			p->bo_list->array[i].bo_va = amdgpu_vm_bo_find(vm, bo);
-		}
+		amdgpu_bo_list_for_each_entry(e, p->bo_list)
+			e->bo_va = amdgpu_vm_bo_find(vm, e->robj);
 	} else {
 		gds = p->adev->gds.gds_gfx_bo;
 		gws = p->adev->gds.gws_gfx_bo;
@@ -753,10 +746,7 @@ error_validate:
 error_free_pages:
 
 	if (p->bo_list) {
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			e = &p->bo_list->array[i];
-
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
 			if (!e->user_pages)
 				continue;
 
@@ -830,7 +820,7 @@ static int amdgpu_bo_vm_update_pte(struc
 	struct amdgpu_vm *vm = &fpriv->vm;
 	struct amdgpu_bo_va *bo_va;
 	struct amdgpu_bo *bo;
-	int i, r;
+	int r;
 
 	r = amdgpu_vm_clear_freed(adev, vm, NULL);
 	if (r)
@@ -861,15 +851,17 @@ static int amdgpu_bo_vm_update_pte(struc
 	}
 
 	if (p->bo_list) {
-		for (i = 0; i < p->bo_list->num_entries; i++) {
+		struct amdgpu_bo_list_entry *e;
+
+		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
 			struct dma_fence *f;
 
 			/* ignore duplicates */
-			bo = p->bo_list->array[i].robj;
+			bo = e->robj;
 			if (!bo)
 				continue;
 
-			bo_va = p->bo_list->array[i].bo_va;
+			bo_va = e->bo_va;
 			if (bo_va == NULL)
 				continue;
 
@@ -898,14 +890,15 @@ static int amdgpu_bo_vm_update_pte(struc
 		return r;
 
 	if (amdgpu_vm_debug && p->bo_list) {
+		struct amdgpu_bo_list_entry *e;
+
 		/* Invalidate all BOs to test for userspace bugs */
-		for (i = 0; i < p->bo_list->num_entries; i++) {
+		amdgpu_bo_list_for_each_entry(e, p->bo_list) {
 			/* ignore duplicates */
-			bo = p->bo_list->array[i].robj;
-			if (!bo)
+			if (!e->robj)
 				continue;
 
-			amdgpu_vm_bo_invalidate(adev, bo, false);
+			amdgpu_vm_bo_invalidate(adev, e->robj, false);
 		}
 	}
 
@@ -1225,16 +1218,16 @@ static int amdgpu_cs_submit(struct amdgp
 	struct drm_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
 	enum drm_sched_priority priority;
 	struct amdgpu_job *job;
-	unsigned i;
 	uint64_t seq;
 
 	int r;
 
 	amdgpu_mn_lock(p->mn);
 	if (p->bo_list) {
-		for (i = p->bo_list->first_userptr;
-		     i < p->bo_list->num_entries; ++i) {
-			struct amdgpu_bo *bo = p->bo_list->array[i].robj;
+		struct amdgpu_bo_list_entry *e;
+
+		amdgpu_bo_list_for_each_userptr_entry(e, p->bo_list) {
+			struct amdgpu_bo *bo = e->robj;
 
 			if (amdgpu_ttm_tt_userptr_needs_pages(bo->tbo.ttm)) {
 				amdgpu_mn_unlock(p->mn);
