From: Jiri Slaby <jslaby@suse.cz>
Date: Thu, 30 Jan 2014 17:21:49 +0100
Subject: kgr: handle irqs
Patch-mainline: not yet, kgraft
References: fate#313296 bnc#912278

Introduce a per-cpu flag to check whether we should use the old or new
function in the slow stub. The new function starts being used on a
processor only after a scheduled function sets the flag via
schedule_on_each_cpu. Presumably this happens in the process context,
no irq is running. And protect the flag setting by disabling
interrupts so that we 1) have a barrier and 2) no interrupt triggers
while setting the flag (but the set should be atomic anyway as it is
bool).

js: fix fail paths
js: make the logic more readable
js: fix allocation order
pm: handle IRQ context using global variable

Signed-off-by: Petr Mladek <pmladek@suse.cz> [fixes]
Signed-off-by: Jiri Slaby <jslaby@suse.cz>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: Frederic Weisbecker <fweisbec@gmail.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
---
 include/linux/kgraft.h |    5 +++++
 kernel/kgraft.c        |   39 ++++++++++++++++++++++++++++++++++++---
 2 files changed, 41 insertions(+), 3 deletions(-)

--- a/include/linux/kgraft.h
+++ b/include/linux/kgraft.h
@@ -18,6 +18,7 @@
 #define LINUX_KGRAFT_H
 
 #include <linux/bitops.h>
+#include <linux/compiler.h>
 #include <linux/kobject.h>
 #include <linux/ftrace.h>
 #include <linux/sched.h>
@@ -28,6 +29,8 @@
 
 #define KGR_TIMEOUT 2
 
+struct kgr_patch;
+
 /**
  * struct kgr_patch_fun -- state of a single function in a kGraft patch
  *
@@ -38,6 +41,8 @@
  * @ftrace_ops_fast: ftrace ops for fast () stub
  */
 struct kgr_patch_fun {
+	struct kgr_patch *patch;
+
 	const char *name;
 	void *new_fun;
 
--- a/kernel/kgraft.c
+++ b/kernel/kgraft.c
@@ -17,10 +17,12 @@
 #include <linux/bitmap.h>
 #include <linux/bug.h>
 #include <linux/ftrace.h>
+#include <linux/hardirq.h> /* for in_interrupt() */
 #include <linux/kallsyms.h>
 #include <linux/kgraft.h>
 #include <linux/livepatch.h>
 #include <linux/module.h>
+#include <linux/percpu.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/sort.h>
@@ -35,6 +37,7 @@ static void kgr_work_fn(struct work_stru
 static struct workqueue_struct *kgr_wq;
 static DECLARE_DELAYED_WORK(kgr_work, kgr_work_fn);
 static DEFINE_MUTEX(kgr_in_progress_lock);
+static bool __percpu *kgr_irq_use_new;
 bool kgr_in_progress;
 static bool kgr_initialized;
 static struct kgr_patch *kgr_patch;
@@ -70,7 +73,9 @@ static notrace void kgr_stub_slow(unsign
 	struct kgr_patch_fun *p = ops->private;
 	bool go_new;
 
-	if (test_bit(0, kgr_immutable)) {
+	if (in_interrupt()) {
+		go_new = *this_cpu_ptr(kgr_irq_use_new);
+	} else if (test_bit(0, kgr_immutable)) {
 		klp_kgraft_mark_task_in_progress(current);
 		go_new = false;
 	} else {
@@ -150,6 +155,8 @@ static void kgr_finalize(void)
 		}
 	}
 
+	free_percpu(kgr_irq_use_new);
+
 	if (kgr_revert)
 		module_put(kgr_patch->owner);
 
@@ -245,6 +252,20 @@ static unsigned long kgr_get_function_ad
 	return orig_addr;
 }
 
+static void kgr_handle_irq_cpu(struct work_struct *work)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	*this_cpu_ptr(kgr_irq_use_new) = true;
+	local_irq_restore(flags);
+}
+
+static void kgr_handle_irqs(void)
+{
+	schedule_on_each_cpu(kgr_handle_irq_cpu);
+}
+
 static int kgr_switch_fops(struct kgr_patch_fun *patch_fun,
 		struct ftrace_ops *new_fops, struct ftrace_ops *unreg_fops)
 {
@@ -391,6 +412,13 @@ int kgr_modify_kernel(struct kgr_patch *
 		goto err_unlock;
 	}
 
+	kgr_irq_use_new = alloc_percpu(bool);
+	if (!kgr_irq_use_new) {
+		pr_err("kgr: can't patch, cannot allocate percpu data\n");
+		ret = -ENOMEM;
+		goto err_unlock;
+	}
+
 	pr_info("kgr: %sing patch '%s'\n", revert ? "revert" : "apply",
 			patch->name);
 
@@ -398,6 +426,8 @@ int kgr_modify_kernel(struct kgr_patch *
 	wmb(); /* set_bit before kgr_handle_processes */
 
 	kgr_for_each_patch_fun(patch, patch_fun) {
+		patch_fun->patch = patch;
+
 		ret = kgr_patch_code(patch_fun, false, revert);
 		/*
 		 * In case any of the symbol resolutions in the set
@@ -410,7 +440,7 @@ int kgr_modify_kernel(struct kgr_patch *
 				if (patch_fun->state == KGR_PATCH_SLOW)
 					kgr_ftrace_disable(patch_fun,
 						&patch_fun->ftrace_ops_slow);
-			goto err_unlock;
+			goto err_free;
 		}
 	}
 	kgr_in_progress = true;
@@ -418,6 +448,7 @@ int kgr_modify_kernel(struct kgr_patch *
 	kgr_revert = revert;
 	mutex_unlock(&kgr_in_progress_lock);
 
+	kgr_handle_irqs();
 	kgr_handle_processes();
 	wmb(); /* clear_bit after kgr_handle_processes */
 	clear_bit(0, kgr_immutable);
@@ -434,6 +465,8 @@ int kgr_modify_kernel(struct kgr_patch *
 	queue_delayed_work(kgr_wq, &kgr_work, KGR_TIMEOUT * HZ);
 
 	return 0;
+err_free:
+	free_percpu(kgr_irq_use_new);
 err_unlock:
 	mutex_unlock(&kgr_in_progress_lock);
 
@@ -444,7 +477,7 @@ err_unlock:
  * kgr_patch_kernel -- the entry for a kgraft patch
  * @patch: patch to be applied
  *
- * Start patching of code that is not running in IRQ context.
+ * Start patching of code.
  */
 int kgr_patch_kernel(struct kgr_patch *patch)
 {
